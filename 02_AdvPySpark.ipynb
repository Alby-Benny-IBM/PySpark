{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alby-Benny-IBM/PySpark/blob/main/02_AdvPySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vplvTnc9mXH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "conf = SparkConf().setAppName(\"MySparkApp\").setMaster(\"local\")\n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "TxAU5tcEmnpq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1,2,3,4,5])\n",
        "rdd_mapped = rdd.map(lambda x: x*2)\n",
        "print(rdd_mapped.collect())\n",
        "\n",
        "rdd_filtered = rdd.filter(lambda x: x % 2 == 0)\n",
        "print(rdd_filtered.collect())"
      ],
      "metadata": {
        "id": "bCfxbbjnabuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716f3ad7-5bac-4794-d116-83ee5ca7443f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8, 10]\n",
            "[2, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_reduce = rdd.reduce(lambda x, y: x + y)\n",
        "print(rdd_reduce)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvD2dbGrmkV8",
        "outputId": "853c24ae-fb0e-46ef-e175-fbd79de614c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([4,9,5])\n",
        "\n",
        "rdd_flat = rdd.flatMap(lambda x: range(x, x+3))\n",
        "print(rdd_flat.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2GAglcFqErf",
        "outputId": "92757eed-5dfa-40c7-cfe0-606b047cf0b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 5, 6, 9, 10, 11, 5, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize(['hello','world'])\n",
        "\n",
        "rdd_flat=rdd.flatMap(lambda x: list(x))\n",
        "print(rdd_flat.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSimljoprYyp",
        "outputId": "33fb9af7-17cb-4cd6-99e1-3931a683f16f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([[1,2],[3,4],[5]])\n",
        "rdd_flat =rdd.flatMap(lambda x: x)\n",
        "print(rdd_flat.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1rBnN4usnic",
        "outputId": "c73b6a24-f8cb-437a-dff8-aea09e75fbc2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1,2,3,4,5])\n",
        "rdd_group= rdd.groupBy(lambda x: \"even\" if x%2 == 0 else \"odd\")\n",
        "print([(key, list(value)) for (key, value) in rdd_group.collect()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ujSkvxxgYg",
        "outputId": "5777113f-15b7-4d76-fe1a-b8d45a2acbdb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('odd', <pyspark.resultiterable.ResultIterable object at 0x7df5d8df5ad0>), ('even', <pyspark.resultiterable.ResultIterable object at 0x7df5d8dc5210>)]\n",
            "[('odd', [1, 3, 5]), ('even', [2, 4])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, \"John\", \"HR\", 5000),\n",
        "    (2, \"Jane\", \"IT\", 8000),\n",
        "    (3, \"Mike\", \"IT\", 6000),\n",
        "    (4, \"Sara\", \"Finance\", 7000),\n",
        "    (5, \"David\", \"HR\", 5500)\n",
        "]\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"DataFrameOperations\").getOrCreate()\n",
        "\n",
        "# Define column names\n",
        "columns = [\"ID\", \"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "# Create a DataFrame from the sample data\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4NTnyVhxtUm",
        "outputId": "ceb5ebd2-079d-4ea0-858d-cc2ad6f526c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+------+\n",
            "| ID| Name|Department|Salary|\n",
            "+---+-----+----------+------+\n",
            "|  1| John|        HR|  5000|\n",
            "|  2| Jane|        IT|  8000|\n",
            "|  3| Mike|        IT|  6000|\n",
            "|  4| Sara|   Finance|  7000|\n",
            "|  5|David|        HR|  5500|\n",
            "+---+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.Salary > 6000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xV4K6Yr7Poc",
        "outputId": "14891227-0776-4499-9cb3-6572979a21fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----------+------+\n",
            "| ID|Name|Department|Salary|\n",
            "+---+----+----------+------+\n",
            "|  2|Jane|        IT|  8000|\n",
            "|  4|Sara|   Finance|  7000|\n",
            "+---+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"Bonus\")"
      ],
      "metadata": {
        "id": "q6Zks0Mv8ELw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.withColumnRenamed(\"Salary\",\"Salary_After_Tax\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6LnckeX8zyM",
        "outputId": "5e46a882-c4cc-4aaf-f154-a669532a01fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+----------------+\n",
            "| ID| Name|Department|Salary_After_Tax|\n",
            "+---+-----+----------+----------------+\n",
            "|  1| John|        HR|            5000|\n",
            "|  2| Jane|        IT|            8000|\n",
            "|  3| Mike|        IT|            6000|\n",
            "|  4| Sara|   Finance|            7000|\n",
            "|  5|David|        HR|            5500|\n",
            "+---+-----+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "df.groupBy(\"Department\").agg(avg(\"Salary_After_Tax\").alias(\"Avg_Salary\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEndf-GM895e",
        "outputId": "ccfdefcb-8deb-49f9-ec55-4659896b24f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Department|Avg_Salary|\n",
            "+----------+----------+\n",
            "|        HR|    5250.0|\n",
            "|   Finance|    7000.0|\n",
            "|        IT|    7000.0|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk5acto99M6u",
        "outputId": "70e29947-a6f7-42d4-e744-965a527e9faa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|Department|count|\n",
            "+----------+-----+\n",
            "|        HR|    2|\n",
            "|   Finance|    1|\n",
            "|        IT|    2|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort(df[\"Salary_After_Tax\"].desc()).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOCZ9mqr9ZKH",
        "outputId": "04c5167a-6931-407b-b483-9da52e8b25a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----------+----------------+\n",
            "| ID|Name|Department|Salary_After_Tax|\n",
            "+---+----+----------+----------------+\n",
            "|  2|Jane|        IT|            8000|\n",
            "|  4|Sara|   Finance|            7000|\n",
            "|  3|Mike|        IT|            6000|\n",
            "+---+----+----------+----------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = df.collect()\n",
        "for row in data_list:\n",
        "    print(row.Name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8aN3EJf9upN",
        "outputId": "43429e3f-b3e8-43f4-d33d-6d56a62194d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John\n",
            "Jane\n",
            "Mike\n",
            "Sara\n",
            "David\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "rdd = sc.parallelize([Row(name=\"Alice\", age =25), Row(name=\"bob\",age=30)])\n",
        "df= spark.createDataFrame(rdd)\n",
        "filtered_df = df.filter(df.age > 25)\n",
        "selected_df=filtered_df.select(\"name\")\n",
        "selected_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqsVl3ML-XvZ",
        "outputId": "31979823-8d6d-425f-a56d-1fc1af287a43"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|name|\n",
            "+----+\n",
            "| bob|\n",
            "+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkSQLBasics\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", \"Sales\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500),\n",
        "    (4, \"David\", \"Sales\", 4500),\n",
        "    (5, \"Eva\", \"IT\", 4200)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t2EtRIiAU3w",
        "outputId": "4ea321ff-0073-4bb3-c516-a9862269816f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "|    4|David|     Sales|  4500|\n",
            "|    5|  Eva|        IT|  4200|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to RDD\n",
        "rdd = df.rdd\n",
        "print(\"RDD Example\",rdd.map(lambda x: (x.Name,x.Salary)).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3EWzHHrCXwE",
        "outputId": "76b53aec-9563-4465-ec43-34ff9719467c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD Example [('Alice', 3000), ('Bob', 4000), ('Cathy', 3500), ('David', 4500), ('Eva', 4200)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"employees\")\n",
        "strSQL=\"select * from employees\"\n",
        "sql_result=spark.sql(strSQL)\n",
        "sql_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuwbbtyyCb1p",
        "outputId": "f9d03b47-93d7-4326-a51c-fad7fb1df294"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "|    4|David|     Sales|  4500|\n",
            "|    5|  Eva|        IT|  4200|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, \"Alice\", \"Sales\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "282VbIDDDh7Y",
        "outputId": "2ec3ffd5-003d-4819-bb38-73d3f8b2f916"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.mode(\"overwrite\").json(\"json_data\")"
      ],
      "metadata": {
        "id": "2_KGjnAEEw3z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/json_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7SslrPAFJ6U",
        "outputId": "5d6becd6-72f1-4363-89c8-d14be6d0bd5d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000-53abce00-0fac-4a14-940c-9563af0bd413-c000.json  _SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/json_data/part-00000-53abce00-0fac-4a14-940c-9563af0bd413-c000.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N83OqOeFNbO",
        "outputId": "88629e79-616f-4808-cc3a-24643394374d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"EmpID\":1,\"Name\":\"Alice\",\"Department\":\"Sales\",\"Salary\":3000}\n",
            "{\"EmpID\":2,\"Name\":\"Bob\",\"Department\":\"IT\",\"Salary\":4000}\n",
            "{\"EmpID\":3,\"Name\":\"Cathy\",\"Department\":\"HR\",\"Salary\":3500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_df = spark.read.json(\"json_data\")\n",
        "json_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfmnltD8Ff3y",
        "outputId": "745b9c4c-d15c-4a09-f777-c5f4a3742638"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+------+\n",
            "|Department|EmpID| Name|Salary|\n",
            "+----------+-----+-----+------+\n",
            "|     Sales|    1|Alice|  3000|\n",
            "|        IT|    2|  Bob|  4000|\n",
            "|        HR|    3|Cathy|  3500|\n",
            "+----------+-----+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPkjvzw4G4Y-",
        "outputId": "c70350b4-dc2d-4f1c-de51-b480b488cd34"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strPath =\"csv_data\"\n",
        "df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(strPath)"
      ],
      "metadata": {
        "id": "UjPIBdy5Fr9L"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_df=spark.read.option(\"header\",\"true\").csv(strPath)\n",
        "csv_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6E4S4-PGks2",
        "outputId": "3c0ab437-e94f-41eb-b94a-74b29f0dbb90"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "# Generate 30 records with random data\n",
        "names = [\"John\", \"Jane\", \"Mike\", \"Sara\", \"David\", \"Emily\", \"George\", \"Nina\", \"Tom\", \"Anna\"]\n",
        "departments = [\"Sales\", \"IT\", \"HR\", \"Finance\", \"Marketing\"]\n",
        "salaries = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "\n",
        "# Create and open a CSV file for writing\n",
        "with open('employee_data.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header\n",
        "    writer.writerow([\"ID\", \"Name\", \"Department\", \"Salary\"])\n",
        "\n",
        "    # Write the 30 records\n",
        "    for i in range(1, 31):\n",
        "        name = random.choice(names)\n",
        "        department = random.choice(departments)\n",
        "        salary = random.choice(salaries)\n",
        "        writer.writerow([i, name, department, salary])\n",
        "\n",
        "print(\"CSV file 'employee_data.csv' has been generated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzP1PN-wGpbd",
        "outputId": "80d35dd1-d830-4a3c-8d26-7ceab606a7c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'employee_data.csv' has been generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat employee_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH1OP6AloyQ4",
        "outputId": "1f613e18-a07a-488c-fbc3-ac17540698c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID,Name,Department,Salary\r\n",
            "1,George,Marketing,8000\r\n",
            "2,Tom,Marketing,4000\r\n",
            "3,Jane,IT,4000\r\n",
            "4,Anna,Marketing,7000\r\n",
            "5,Jane,HR,9000\r\n",
            "6,Anna,IT,3000\r\n",
            "7,George,HR,8000\r\n",
            "8,John,HR,4000\r\n",
            "9,Anna,Marketing,4000\r\n",
            "10,John,IT,8000\r\n",
            "11,George,Marketing,4000\r\n",
            "12,David,Marketing,8000\r\n",
            "13,Sara,IT,8000\r\n",
            "14,Mike,Sales,7000\r\n",
            "15,David,Finance,8000\r\n",
            "16,Mike,Sales,9000\r\n",
            "17,Tom,IT,10000\r\n",
            "18,Emily,Finance,6000\r\n",
            "19,George,Marketing,4000\r\n",
            "20,Mike,Sales,7000\r\n",
            "21,Sara,HR,4000\r\n",
            "22,Emily,Finance,6000\r\n",
            "23,George,HR,3000\r\n",
            "24,Jane,Finance,6000\r\n",
            "25,Anna,Sales,6000\r\n",
            "26,George,Finance,9000\r\n",
            "27,George,Marketing,8000\r\n",
            "28,David,IT,9000\r\n",
            "29,Anna,IT,3000\r\n",
            "30,David,IT,6000\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p empdata/\n",
        "!mv employee_data.csv empdata/"
      ],
      "metadata": {
        "id": "YeU1lggSo4ro"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"EmpID\", IntegerType()),\n",
        "    StructField(\"Name\", StringType()),\n",
        "    StructField(\"Department\", StringType()),\n",
        "    StructField(\"Salary\", IntegerType())\n",
        "])"
      ],
      "metadata": {
        "id": "Zp1KiOVspcaN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"StreamingExample\").getOrCreate()\n",
        "\n",
        "stream_df = spark.readStream.option(\"sep\",\",\").schema(schema).csv(\"/content/empdata/\")\n"
      ],
      "metadata": {
        "id": "ScFYysLqqN_N"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper\n",
        "\n",
        "transform_df=stream_df.withColumn(\"NameUpper\",upper(\"Name\"))"
      ],
      "metadata": {
        "id": "EosIJfeAsZ0Y"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = transform_df.writeStream.format(\"console\").outputMode(\"append\").start()\n",
        "\n",
        "query.awaitTermination()"
      ],
      "metadata": {
        "id": "m4SqR0jDsmvK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "import time\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directory if not exists\n",
        "file_dir = '/content/drive/MyDrive/newData/'\n",
        "os.makedirs(file_dir, exist_ok=True)\n",
        "\n",
        "# Data sources\n",
        "names = [\"John\", \"Jane\", \"Mike\", \"Sara\", \"David\", \"Emily\", \"George\", \"Nina\", \"Tom\", \"Anna\"]\n",
        "departments = [\"Sales\", \"IT\", \"HR\", \"Finance\", \"Marketing\"]\n",
        "salaries = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "\n",
        "i = 1          # Global record counter\n",
        "j = 0          # File counter\n",
        "temp = 0       # Row counter in current file\n",
        "max_rows = 10  # Rows per file\n",
        "\n",
        "while True:\n",
        "    # Create new file if temp == 0\n",
        "    if temp == 0:\n",
        "        file_path = os.path.join(file_dir, f\"streamed_data{j}.csv\")\n",
        "        with open(file_path, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"ID\", \"Name\", \"Department\", \"Salary\"])\n",
        "        print(f\"Created new file: {file_path}\")\n",
        "\n",
        "    # Generate record\n",
        "    name = random.choice(names)\n",
        "    department = random.choice(departments)\n",
        "    salary = random.choice(salaries)\n",
        "    record = [i, name, department, salary]\n",
        "    print(record)\n",
        "\n",
        "    # Append to current file\n",
        "    with open(file_path, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(record)\n",
        "\n",
        "    # Update counters\n",
        "    i += 1\n",
        "    temp += 1\n",
        "\n",
        "    # Rotate file if max_rows reached\n",
        "    if temp == max_rows:\n",
        "        temp = 0\n",
        "        j += 1\n",
        "\n",
        "    time.sleep(1)\n"
      ],
      "metadata": {
        "id": "HGcmmDL2-hFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/drive/MyDrive/newData/streamed_data*.csv"
      ],
      "metadata": {
        "id": "zl344hR8C0QT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRCij2EPDhAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}